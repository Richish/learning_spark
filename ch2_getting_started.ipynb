{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:18.630742Z",
     "start_time": "2020-07-26T02:05:18.367026Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import, build spark session, load data into spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:36.469070Z",
     "start_time": "2020-07-26T02:05:18.632340Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PythonMnMCount\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:40.080491Z",
     "start_time": "2020-07-26T02:05:36.470942Z"
    }
   },
   "outputs": [],
   "source": [
    "mnm_file = \"data/mnm_dataset.csv\"\n",
    "mnm_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(mnm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:40.111363Z",
     "start_time": "2020-07-26T02:05:40.084453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_collectAsArrow',\n",
       " '_jcols',\n",
       " '_jdf',\n",
       " '_jmap',\n",
       " '_jseq',\n",
       " '_lazy_rdd',\n",
       " '_repr_html_',\n",
       " '_sc',\n",
       " '_schema',\n",
       " '_sort_cols',\n",
       " '_support_repr_html',\n",
       " 'agg',\n",
       " 'alias',\n",
       " 'approxQuantile',\n",
       " 'cache',\n",
       " 'checkpoint',\n",
       " 'coalesce',\n",
       " 'colRegex',\n",
       " 'collect',\n",
       " 'columns',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'createGlobalTempView',\n",
       " 'createOrReplaceGlobalTempView',\n",
       " 'createOrReplaceTempView',\n",
       " 'createTempView',\n",
       " 'crossJoin',\n",
       " 'crosstab',\n",
       " 'cube',\n",
       " 'describe',\n",
       " 'distinct',\n",
       " 'drop',\n",
       " 'dropDuplicates',\n",
       " 'drop_duplicates',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'exceptAll',\n",
       " 'explain',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'foreach',\n",
       " 'foreachPartition',\n",
       " 'freqItems',\n",
       " 'groupBy',\n",
       " 'groupby',\n",
       " 'head',\n",
       " 'hint',\n",
       " 'intersect',\n",
       " 'intersectAll',\n",
       " 'isLocal',\n",
       " 'isStreaming',\n",
       " 'is_cached',\n",
       " 'join',\n",
       " 'limit',\n",
       " 'localCheckpoint',\n",
       " 'na',\n",
       " 'orderBy',\n",
       " 'persist',\n",
       " 'printSchema',\n",
       " 'randomSplit',\n",
       " 'rdd',\n",
       " 'registerTempTable',\n",
       " 'repartition',\n",
       " 'repartitionByRange',\n",
       " 'replace',\n",
       " 'rollup',\n",
       " 'sample',\n",
       " 'sampleBy',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'selectExpr',\n",
       " 'show',\n",
       " 'sort',\n",
       " 'sortWithinPartitions',\n",
       " 'sql_ctx',\n",
       " 'stat',\n",
       " 'storageLevel',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'take',\n",
       " 'toDF',\n",
       " 'toJSON',\n",
       " 'toLocalIterator',\n",
       " 'toPandas',\n",
       " 'union',\n",
       " 'unionAll',\n",
       " 'unionByName',\n",
       " 'unpersist',\n",
       " 'where',\n",
       " 'withColumn',\n",
       " 'withColumnRenamed',\n",
       " 'withWatermark',\n",
       " 'write',\n",
       " 'writeStream']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform some narrow transformations(like filter), wide transformations (like groupby, agg, orderby) and some action (like show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:42.053341Z",
     "start_time": "2020-07-26T02:05:40.117082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|WY   |Green |1695 |\n",
      "|CO   |Blue  |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1673 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1663 |\n",
      "|WA   |Orange|1658 |\n",
      "|NV   |Brown |1657 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CO   |Brown |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1646 |\n",
      "|OR   |Red   |1645 |\n",
      "|UT   |Yellow|1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|TX   |Blue  |1614 |\n",
      "|OR   |Yellow|1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mnm_df.show(2)\n",
    "count_mnm_df = mnm_df.select(\"State\", \"Color\", \"Count\").groupBy(\"State\", \"Color\").agg(count(\"Count\").alias(\"Total\")).orderBy(\"Total\", ascending=False)\n",
    "count_mnm_df.show(60, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:43.563608Z",
     "start_time": "2020-07-26T02:05:42.055508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:44.166304Z",
     "start_time": "2020-07-26T02:05:43.565699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|CA   |Green |1723 |\n",
      "|CA   |Brown |1718 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CA   |Blue  |1603 |\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ca_count_mnm_df = (mnm_df\n",
    ".select(\"State\", \"Color\", \"Count\")\n",
    ".where(mnm_df.State == \"CA\")\n",
    ".groupBy(\"State\", \"Color\")\n",
    ".agg(count(\"Count\").alias(\"Total\"))\n",
    ".orderBy(\"Total\", ascending=False))\n",
    "# Show the resulting aggregation for California.\n",
    "ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stop the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:44.490672Z",
     "start_time": "2020-07-26T02:05:44.173238Z"
    }
   },
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T02:05:44.494666Z",
     "start_time": "2020-07-26T02:05:44.492374Z"
    }
   },
   "outputs": [],
   "source": [
    "#exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T23:25:44.218542Z",
     "start_time": "2020-07-28T23:25:43.530258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Total|\n",
      "+-----+\n",
      "|10164|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=mnm_df.select(\"State\", \"Color\", \"Count\").where(mnm_df.State == \"CA\").agg(count(\"Count\").alias(\"Total\")).show(n=10, truncate=False)\n",
    "#a #.agg(count(\"Count\").alias(\"Total\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance comparison with pandas df for same query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T23:27:35.067167Z",
     "start_time": "2020-07-28T23:27:34.897434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   State   99999 non-null  object\n",
      " 1   Color   99999 non-null  object\n",
      " 2   Count   99999 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/mnm_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T23:30:59.049903Z",
     "start_time": "2020-07-28T23:30:59.004267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10164"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf=df[[\"State\", \"Color\", \"Count\"]]\n",
    "fdf[df.State==\"CA\"][\"Count\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|# Learning Spark 2nd Edition                                                                                                                                                                                                                                  |\n",
      "|Welcome to the GitHub repo for Learning Spark 2nd Edition.                                                                                                                                                                                                    |\n",
      "|Chapters [2](chapter2/README.md), [3](chapter3/README.md), [6](chapter6/README.md), and [7](chapter7/README.md) contain stand-alone Spark applications. You can build all the JAR files for each chapter by running the Python script: `python build_jars.py`.|\n",
      "|don't have to prefix `SPARK_HOME/bin/spark-submit` for these standalone applications.                                                                                                                                                                         |\n",
      "|For all the other chapters, we have provided notebooks in the [notebooks](notebooks) folder. We have also included notebook equivalents for a few of the stand-alone Spark applications in the aforementioned chapters.                                       |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## filtering example\n",
    "strings = spark.read.text(\"data/README.md\")\n",
    "spark_strings = strings.filter(strings.value.contains(\"Spark\")|strings.value.contains(\"spark\"))\n",
    "spark_strings.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
